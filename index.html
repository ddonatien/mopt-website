<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Disentangling perception and reasoning for improving data efficiency in learning cloth manipulation without demonstrations">
  <meta name="keywords" content="RL, Cloth Manipulation, Data Efficiency, Robotics">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Disentangling perception and reasoning for improving data efficiency in learning cloth manipulation without demonstrations</title>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-Y3C8NHQ8RJ"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-Y3C8NHQ8RJ');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="apple-touch-icon" sizes="180x180" href="./static/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="./static/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="./static/images/favicon-16x16.png">
  <link rel="manifest" href="./static/images/site.webmanifest">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://ddonatien.github.io">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://ddonatien.github.io/garfield-website">
            GARField
          </a>
        </div>
      </div>
    </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Disentangling perception and reasoning for improving data efficiency in learning cloth manipulation without demonstrations</h1>
          <div class="is-size-3 publication-target">
            <span>--</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://ddonatien.github.io/">Donatien Delehelle</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="https://feichenlab.com/members/">Fei Chen</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.iit.it/people-details/-/people/darwin-caldwell">Darwin Caldwell</a><sup>2</sup>,</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Genova,</span>
            <span class="author-block"><sup>2</sup>Istituto Italiano di Tecnologia,</span>
            <span class="author-block"><sup>3</sup>Chinese University of Hong Kong</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2601.21713"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=NpEaa2P7qZI"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/ddonatien/mopt_cloth"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/expes.mp4"
                type="video/mp4">
        <source src="./static/videos/expes.webm"
                type="video/webm">
      </video>
      <!-- <h2 class="subtitle has-text-centered">
        <span class="dnerf">GARField (Garment Attached Radiance Field)</span> addresses the data problem in garment manipulation through learnable, viewpoint-free data generation.
      </h2> -->
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          Cloth manipulation is an ubiquitous task in everyday life,
          but it is still an open challenge for robotics. The difficulties in
          developing cloth manipulation policies are attributed to the high-dimensional
          state space, complex dynamics, and high propensity to self-occlusion displayed by fabrics.
          As analytical methods haven’t been able to provide robust and general manipulation
          policies, reinforcement learning (RL) is seen as a promising approach to these problems.
          </p>
          <p>
          However, in order to address the large state space and the complex dynamics,
          data-based methods usually rely on big models and long training times.
          The inferred computational cost significantly hampers the development and adoption
          of these methods.
          Additionally, because of the challenge of robust state estimation,
          garment manipulation policies usually adopt an end-to-end learning approach
          with workspace images as input. While this approach allows for a conceptually
          trivial sim-to-real transfer via real-world fine-tuning, it also impairs a
          significant computational cost on the training on agents with a very
          lossy representation of the environment state. 
          </p>
          <p>
          This paper aims at questioning this common design choice by exploring an efficient
          and modular approach to RL for cloth manipulation. We show that through careful design
          choices, we can significantly reduce model size and training time when learning in
          simulation.
          Additionally, we showcase how our optimal simulation-based model can be transferred to
          the real-word. We evaluate our work on the Softgym benchmark and achieve a significant
          performance improvements over available baselines on our task, with a significantly
          smaller model.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Video generation</h2>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/sock_fall_render.mp4"
                  type="video/mp4">
          <source src="./static/videos/sock_fall_render.webm"
                  type="video/webm">
          <source src="./static/videos/sock_fall_render.ogv"
                  type="video/ogg">
          Your browser doesn't seem to support the video tag.
          </video>
        </div>
      </div>
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Re-posed mesh image</h2>
          <img src="./static/images/image_gen.png" class="reposed_image" alt="Image of re-posed mesh" width="320px"/>
        </div>
      </div>
    </div> -->
    <!--/ Matting. -->

    <!-- Overview. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Overview</h2>

        <div class="content has-text-justified">
          <p>
            GARField models the scene as a composition of signed distance and visual feature fields. The background field is defined in the
            scene’s global coordinates frame. The other fields are attached to objects’ meshes and can be re-posed. The mesh-attached coordinates
            system projects query points in a coordinate system made up of the point’s distance to the mesh’s surface and coordinates of the surface-projection
            of the query point in a bespoke coordinate system built around Laplacian-based position embeddings and barycentric coordinates.
          </p>
        </div>
        <div class="columns is-vcentered overview-image">
            <img src="./static/images/overview.png"
                 class="overview-image"
                 alt="Architecture overview image."/>
        </div>

        <h2 class="title is-3">Reconstruction performance</h2>

        <div class="columns is-vcentered overview-image">
            <img src="./static/images/qual_1.png"
                 class="overview-image"
                 alt="Architecture overview image."/>
        </div>
        <br/>
      </div>
    </div> -->

    <!-- Concurrent Work. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

         <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div> -->
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
 <div class="container is-max-desktop content">
   <h2 class="title">BibTeX</h2>
   <pre><code>@misc{delehelle2026disentanglingperceptionreasoningimproving,
      title={Disentangling perception and reasoning for improving data efficiency in learning cloth manipulation without demonstrations}, 
      author={Donatien Delehelle and Fei Chen and Darwin Caldwell},
      year={2026},
      eprint={2601.21713},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2601.21713}, 
}</code></pre>
</div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <!-- <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a> -->
      <a class="icon-link" href="https://github.com/ddonatien" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            The template of this website was borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">nerfies</a>. Check them out !
          </p>
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
